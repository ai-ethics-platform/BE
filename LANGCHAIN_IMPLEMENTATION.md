# LangChainì„ í™œìš©í•œ êµ¬ì¡°í™”ëœ JSON ì‘ë‹µ íŒŒì‹± êµ¬í˜„ê¸°

## ğŸ“‹ ëª©ì°¨
1. [ë¬¸ì œ ìƒí™©](#ë¬¸ì œ-ìƒí™©)
2. [í•´ê²° ë°©ì•ˆ](#í•´ê²°-ë°©ì•ˆ)
3. [ì•„í‚¤í…ì²˜ ì„¤ê³„](#ì•„í‚¤í…ì²˜-ì„¤ê³„)
4. [êµ¬í˜„ ì„¸ë¶€ì‚¬í•­](#êµ¬í˜„-ì„¸ë¶€ì‚¬í•­)
5. [ì½”ë“œ êµ¬ì¡°](#ì½”ë“œ-êµ¬ì¡°)
6. [ë™ì‘ íë¦„](#ë™ì‘-íë¦„)
7. [ì¥ë‹¨ì  ë¶„ì„](#ì¥ë‹¨ì -ë¶„ì„)
8. [ê²°ë¡ ](#ê²°ë¡ )

---

## ë¬¸ì œ ìƒí™©

### ê¸°ì¡´ ë°©ì‹ì˜ í•œê³„

ë‹¤ë‹¨ê³„ ì±—ë´‡ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ë©´ì„œ ë‹¤ìŒê³¼ ê°™ì€ ë¬¸ì œ:

1. **í”„ë¡ íŠ¸ì—”ë“œ ê·œì¹™ ê¸°ë°˜ íŒŒì‹±ì˜ í•œê³„**
   - OpenAI Playground APIë¡œë¶€í„° ë°›ì€ ììœ  í˜•ì‹ í…ìŠ¤íŠ¸ ì‘ë‹µì—ì„œ ë³€ìˆ˜ë¥¼ ì¶”ì¶œí•´ì•¼ í•¨
   - ì •ê·œí‘œí˜„ì‹ì´ë‚˜ í‚¤ì›Œë“œ ê¸°ë°˜ íŒŒì‹±ìœ¼ë¡œëŠ” ë‹¤ì–‘í•œ ì‘ë‹µ í˜•ì‹ì— ëŒ€ì‘í•˜ê¸° ì–´ë ¤ì›€
   - ì‘ë‹µ í˜•ì‹ì´ ì¡°ê¸ˆë§Œ ë‹¬ë¼ì ¸ë„ íŒŒì‹± ì‹¤íŒ¨

2. **ë‹¤ë‹¨ê³„ ëŒ€í™” íë¦„ ê´€ë¦¬ì˜ ë³µì¡ì„±**
   - ê° ë‹¨ê³„(`opening` â†’ `dilemma` â†’ `flip` â†’ `roles` â†’ `ending`)ë§ˆë‹¤ ë‹¤ìŒ ë‹¨ê³„ë¡œ ì „ë‹¬í•  ë³€ìˆ˜ê°€ ë‹¤ë¦„
   - ì˜ˆ: `opening` ë‹¨ê³„ì—ì„œëŠ” `topic` ë³€ìˆ˜ë¥¼ ì¶”ì¶œí•´ì•¼ í•˜ê³ , `dilemma` ë‹¨ê³„ì—ì„œëŠ” `question`, `choice1`, `choice2` ë³€ìˆ˜ í•„ìš”
   - í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ê° ë‹¨ê³„ë³„ë¡œ ë‹¤ë¥¸ íŒŒì‹± ë¡œì§ì„ êµ¬í˜„í•´ì•¼ í•˜ëŠ” ë¶€ë‹´

3. **ìœ ì§€ë³´ìˆ˜ì„± ë¬¸ì œ**
   - í”„ë¡¬í”„íŠ¸ê°€ ë³€ê²½ë˜ë©´ íŒŒì‹± ë¡œì§ë„ í•¨ê»˜ ìˆ˜ì •í•´ì•¼ í•¨
   - íŒŒì‹± ì‹¤íŒ¨ ì‹œ ë””ë²„ê¹…ì´ ì–´ë ¤ì›€

### ì˜ˆì‹œ: ê¸°ì¡´ ë°©ì‹ì˜ ë¬¸ì œì 

```python
# í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì‹œë„í–ˆë˜ ë°©ì‹
response_text = "AI ìœ¤ë¦¬ì— ëŒ€í•œ ë”œë ˆë§ˆë¥¼ ì œì‹œí•©ë‹ˆë‹¤. ì£¼ì œ: AI ìœ¤ë¦¬"

# ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ íŒŒì‹± ì‹œë„
import re
topic_match = re.search(r'ì£¼ì œ:\s*(.+)', response_text)
topic = topic_match.group(1) if topic_match else None

# ë¬¸ì œ: ì‘ë‹µ í˜•ì‹ì´ ë°”ë€Œë©´ íŒŒì‹± ì‹¤íŒ¨
# "ì£¼ì œëŠ” AI ìœ¤ë¦¬ì…ë‹ˆë‹¤" â†’ íŒŒì‹± ì‹¤íŒ¨
# "Topic: AI Ethics" â†’ íŒŒì‹± ì‹¤íŒ¨
```

---

## í•´ê²° ë°©ì•ˆ

### LangChain + PydanticOutputParser ì‚¬ìš©ìš©

**í•µì‹¬ ì•„ì´ë””ì–´**: LLMì´ ìƒì„±í•œ ììœ  í˜•ì‹ í…ìŠ¤íŠ¸ë¥¼ ë‹¤ì‹œ LLMì—ê²Œ êµ¬ì¡°í™”ëœ JSONìœ¼ë¡œ ë³€í™˜í•˜ë„ë¡ ìš”ì²­

**ì£¼ìš” ê¸°ìˆ  ìŠ¤íƒ**:
- **LangChain**: LLM ì²´ì¸ êµ¬ì„± ë° ì¶œë ¥ íŒŒì‹±
- **PydanticOutputParser**: Pydantic ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ êµ¬ì¡°í™”ëœ ì¶œë ¥ ê°•ì œ
- **Pydantic**: íƒ€ì… ì•ˆì „ì„±ê³¼ ê²€ì¦ì„ ìœ„í•œ ë°ì´í„° ëª¨ë¸

### ì™œ LangChainì¸ê°€?

1. **êµ¬ì¡°í™”ëœ ì¶œë ¥ ë³´ì¥**: `PydanticOutputParser`ê°€ LLM ì¶œë ¥ì„ ê°•ì œë¡œ JSON í˜•ì‹ìœ¼ë¡œ ë³€í™˜
2. **íƒ€ì… ì•ˆì „ì„±**: Pydantic ëª¨ë¸ë¡œ ìŠ¤í‚¤ë§ˆ ì •ì˜ ë° ìë™ ê²€ì¦
3. **ìœ ì—°í•œ ì²´ì¸ êµ¬ì„±**: í”„ë¡¬í”„íŠ¸ â†’ LLM â†’ íŒŒì„œë¥¼ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ êµ¬ì„±
4. **ì—ëŸ¬ ì²˜ë¦¬**: íŒŒì‹± ì‹¤íŒ¨ ì‹œ graceful fallback ê°€ëŠ¥

---

## ì•„í‚¤í…ì²˜ ì„¤ê³„

### ì „ì²´ íë¦„ë„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  OpenAI         â”‚
â”‚  Playground API â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ ììœ  í˜•ì‹ í…ìŠ¤íŠ¸ ì‘ë‹µ
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Raw Response   â”‚
â”‚  Text           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ LangChain íŒŒì´í”„ë¼ì¸
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. ChatPromptTemplate          â”‚
â”‚     - JSON ë³€í™˜ ì§€ì‹œ            â”‚
â”‚     - Pydantic ìŠ¤í‚¤ë§ˆ ì„¤ëª…      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. ChatOpenAI (gpt-4o-mini)    â”‚
â”‚     - í…ìŠ¤íŠ¸ â†’ JSON ë³€í™˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. PydanticOutputParser        â”‚
â”‚     - JSON â†’ Pydantic ëª¨ë¸      â”‚
â”‚     - íƒ€ì… ê²€ì¦                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Parsed Variables               â”‚
â”‚  {                              â”‚
â”‚    "response_text": "...",      â”‚
â”‚    "topic": "AI ìœ¤ë¦¬",          â”‚
â”‚    ...                          â”‚
â”‚  }                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2ë‹¨ê³„ ì²˜ë¦¬ ë°©ì‹

1. **1ë‹¨ê³„: OpenAI Playground API í˜¸ì¶œ**
   - í”„ë¡¬í”„íŠ¸ IDì™€ ë²„ì „ì„ ì‚¬ìš©í•˜ì—¬ í”„ë¡¬í”„íŠ¸ ì²˜ë¦¬
   - ììœ  í˜•ì‹ í…ìŠ¤íŠ¸ ì‘ë‹µ ë°›ìŒ

2. **2ë‹¨ê³„: LangChainìœ¼ë¡œ êµ¬ì¡°í™”**
   - ë°›ì€ í…ìŠ¤íŠ¸ë¥¼ LangChain íŒŒì´í”„ë¼ì¸ì— ì…ë ¥
   - Pydantic ëª¨ë¸ì— ë§ëŠ” JSONìœ¼ë¡œ ë³€í™˜
   - ë³€ìˆ˜ ì¶”ì¶œ ë° ê²€ì¦

---

## êµ¬í˜„ ì„¸ë¶€ì‚¬í•­

### 1. Pydantic ëª¨ë¸ ì •ì˜

ê° ë‹¨ê³„ë³„ë¡œ í•„ìš”í•œ ë³€ìˆ˜ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì •ì˜:

```python
# app/schemas/step_responses.py

from pydantic import BaseModel, Field
from typing import Optional

class OpeningResponse(BaseModel):
    """opening ë‹¨ê³„ ì‘ë‹µ ëª¨ë¸ - topic ë³€ìˆ˜ ì¶”ì¶œ (dilemma ë‹¨ê³„ì— ì „ë‹¬)"""
    response_text: str = Field(..., description="ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤„ ì‘ë‹µ í…ìŠ¤íŠ¸")
    topic: Optional[str] = Field(None, description="ë‹¤ìŒ ë‹¨ê³„(dilemma)ì— ì „ë‹¬í•  topic ë³€ìˆ˜")

class DilemmaResponse(BaseModel):
    """dilemma ë‹¨ê³„ ì‘ë‹µ ëª¨ë¸ - question, choice1, choice2 ë³€ìˆ˜ ì¶”ì¶œ (flip ë‹¨ê³„ì— ì „ë‹¬)"""
    response_text: str = Field(..., description="ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤„ ì‘ë‹µ í…ìŠ¤íŠ¸")
    question: Optional[str] = Field(None, description="ë‹¤ìŒ ë‹¨ê³„(flip)ì— ì „ë‹¬í•  question ë³€ìˆ˜")
    choice1: Optional[str] = Field(None, description="ë‹¤ìŒ ë‹¨ê³„(flip)ì— ì „ë‹¬í•  choice1 ë³€ìˆ˜")
    choice2: Optional[str] = Field(None, description="ë‹¤ìŒ ë‹¨ê³„(flip)ì— ì „ë‹¬í•  choice2 ë³€ìˆ˜")

class FlipResponse(BaseModel):
    """flip ë‹¨ê³„ ì‘ë‹µ ëª¨ë¸ - structure ë³€ìˆ˜ ì¶”ì¶œ (roles ë‹¨ê³„ì— ì „ë‹¬)"""
    response_text: str = Field(..., description="ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤„ ì‘ë‹µ í…ìŠ¤íŠ¸")
    structure: Optional[str] = Field(None, description="ë‹¤ìŒ ë‹¨ê³„(roles)ì— ì „ë‹¬í•  structure ë³€ìˆ˜")

# ë‹¨ê³„ë³„ ì‘ë‹µ ëª¨ë¸ ë§¤í•‘
STEP_RESPONSE_MODELS = {
    "opening": OpeningResponse,
    "dilemma": DilemmaResponse,
    "flip": FlipResponse,
    "roles": RolesResponse,
    "ending": EndingResponse,
}
```

**í•µì‹¬ í¬ì¸íŠ¸**:
- `Field`ì˜ `description`ì´ LLMì—ê²Œ ê° í•„ë“œì˜ ì˜ë¯¸ë¥¼ ì „ë‹¬
- `Optional` íƒ€ì…ìœ¼ë¡œ íŒŒì‹± ì‹¤íŒ¨ ì‹œì—ë„ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
- ê° ëª¨ë¸ì€ ë‹¤ìŒ ë‹¨ê³„ì— í•„ìš”í•œ ë³€ìˆ˜ë§Œ í¬í•¨

### 2. LangChain íŒŒì´í”„ë¼ì¸ êµ¬ì„±

```python
# app/services/chat_service.py

from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.schema.output_parser import PydanticOutputParser

async def call_openai_response(self, step: str, user_input: str, context: Dict[str, Any]):
    # 1. OpenAI Playground API í˜¸ì¶œ
    response = self.openai_client.responses.create(
        prompt={
            "id": prompt_config["id"],
            "version": prompt_config["version"]
        },
        input=user_input,
        input_variables=input_variables
    )
    
    raw_response_text = extract_text_from_response(response)
    
    # 2. LangChainìœ¼ë¡œ JSON íŒŒì‹±
    parsed_variables = {}
    try:
        # ë‹¨ê³„ë³„ ì‘ë‹µ ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°
        response_model = STEP_RESPONSE_MODELS.get(step)
        if response_model:
            # LLM ì´ˆê¸°í™”
            llm = ChatOpenAI(
                model="gpt-4o-mini",
                temperature=0.7,
                api_key=settings.OPENAI_API_KEY,
            )
            
            # PydanticOutputParser ìƒì„±
            parser = PydanticOutputParser(pydantic_object=response_model)
            
            # JSON í˜•ì‹ ì§€ì‹œì‚¬í•­ ìë™ ìƒì„±
            format_instructions = parser.get_format_instructions()
            
            # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ êµ¬ì„±
            prompt_template = ChatPromptTemplate.from_template(
                """ë‹¤ìŒ ì‘ë‹µì„ JSON í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”. 
ì‘ë‹µ í…ìŠ¤íŠ¸: {raw_response}

{format_instructions}

ì›ë³¸ ì‘ë‹µì˜ ë‚´ìš©ì„ ìœ ì§€í•˜ë©´ì„œ, ìœ„ JSON ìŠ¤í‚¤ë§ˆì— ë§ì¶°ì„œ êµ¬ì¡°í™”í•´ì£¼ì„¸ìš”.
response_text í•„ë“œì—ëŠ” ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤„ ì›ë³¸ ì‘ë‹µ í…ìŠ¤íŠ¸ë¥¼ ë„£ì–´ì£¼ì„¸ìš”."""
            )
            
            # ì²´ì¸ ì‹¤í–‰ (í”„ë¡¬í”„íŠ¸ â†’ LLM â†’ íŒŒì„œ)
            chain = prompt_template | llm | parser
            parsed_result = await chain.ainvoke({
                "raw_response": raw_response_text,
                "format_instructions": format_instructions
            })
            
            # íŒŒì‹±ëœ ê²°ê³¼ì—ì„œ ë³€ìˆ˜ ì¶”ì¶œ
            if isinstance(parsed_result, BaseModel):
                parsed_dict = parsed_result.model_dump()
                # response_textëŠ” ì œì™¸í•˜ê³  ë‚˜ë¨¸ì§€ë¥¼ variablesë¡œ
                parsed_variables = {
                    k: v for k, v in parsed_dict.items() 
                    if k != "response_text"
                }
                
    except Exception as parse_error:
        # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì›ë³¸ í…ìŠ¤íŠ¸ ì‚¬ìš© (graceful fallback)
        pass
    
    return raw_response_text, parsed_variables
```

**í•µì‹¬ í¬ì¸íŠ¸**:
- `PydanticOutputParser`ê°€ ìë™ìœ¼ë¡œ JSON ìŠ¤í‚¤ë§ˆ ì§€ì‹œì‚¬í•­ ìƒì„±
- `chain = prompt_template | llm | parser`ë¡œ íŒŒì´í”„ë¼ì¸ êµ¬ì„±
- íŒŒì‹± ì‹¤íŒ¨ ì‹œì—ë„ ì›ë³¸ í…ìŠ¤íŠ¸ëŠ” ë°˜í™˜ (ì•ˆì •ì„±)

### 3. ì´ë¯¸ì§€ ìƒì„± APIì—ë„ ì ìš©

ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸ë„ êµ¬ì¡°í™”í•˜ì—¬ ë” ì •í™•í•œ ì´ë¯¸ì§€ ìƒì„±:

```python
# app/api/endpoints/chat.py

from app.schemas.chat import GeneratedImage

@router.post("/chat/image")
async def generate_image(payload: ImageRequest):
    # LangChainìœ¼ë¡œ ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸ êµ¬ì¡°í™”
    prompt_template = ChatPromptTemplate.from_template(
        """You are an image generation assistant.
User input: {input}
Variables (context): {variables}

Return a JSON object describing the intended image:
{{
  "description": "detailed content of the image",
  "style": "art style or tone",
  "size": "image size",
  "reasoning": "brief reasoning why this fits the user's intent"
}}"""
    )
    
    parser = PydanticOutputParser(pydantic_object=GeneratedImage)
    chain = prompt_template | llm | parser
    
    parsed_result = await chain.ainvoke({
        "input": payload.input,
        "variables": variables
    })
    
    # êµ¬ì¡°í™”ëœ descriptionì„ DALL-E í”„ë¡¬í”„íŠ¸ë¡œ ì‚¬ìš©
    final_prompt = parsed_result.description
    img = client.images.generate(
        model="dall-e-3",
        prompt=final_prompt,
        size=size,
    )
```

---

## ì½”ë“œ êµ¬ì¡°

### íŒŒì¼ êµ¬ì¡°

```
app/
â”œâ”€â”€ schemas/
â”‚   â”œâ”€â”€ step_responses.py      # ë‹¨ê³„ë³„ Pydantic ì‘ë‹µ ëª¨ë¸
â”‚   â”œâ”€â”€ chat_session.py         # API ìš”ì²­/ì‘ë‹µ ìŠ¤í‚¤ë§ˆ
â”‚   â””â”€â”€ chat.py                 # ì´ë¯¸ì§€ ìƒì„± ìŠ¤í‚¤ë§ˆ
â”œâ”€â”€ services/
â”‚   â””â”€â”€ chat_service.py         # LangChain íŒŒì´í”„ë¼ì¸ ë¡œì§
â””â”€â”€ api/
    â””â”€â”€ endpoints/
        â””â”€â”€ chat.py             # API ì—”ë“œí¬ì¸íŠ¸
```

### ì£¼ìš” ì»´í¬ë„ŒíŠ¸

1. **`STEP_RESPONSE_MODELS`**: ë‹¨ê³„ë³„ ì‘ë‹µ ëª¨ë¸ ë§¤í•‘
2. **`call_openai_response()`**: 2ë‹¨ê³„ ì²˜ë¦¬ ë¡œì§
3. **`PydanticOutputParser`**: JSON íŒŒì‹± ë° ê²€ì¦
4. **`ChatPromptTemplate`**: JSON ë³€í™˜ í”„ë¡¬í”„íŠ¸

---

## ë™ì‘ íë¦„

### ì „ì²´ ì‹œí€€ìŠ¤ ë‹¤ì´ì–´ê·¸ë¨

```
ì‚¬ìš©ì â†’ API ìš”ì²­
  â”‚
  â–¼
[1] OpenAI Playground API í˜¸ì¶œ
  â”‚
  â”œâ”€â†’ í”„ë¡¬í”„íŠ¸ ID: pmpt_xxx
  â”œâ”€â†’ ë²„ì „: 20
  â””â”€â†’ ì‚¬ìš©ì ì…ë ¥ + ì»¨í…ìŠ¤íŠ¸ ë³€ìˆ˜
  â”‚
  â–¼
[2] ììœ  í˜•ì‹ í…ìŠ¤íŠ¸ ì‘ë‹µ ìˆ˜ì‹ 
  â”‚
  â”œâ”€â†’ "ì•ˆë…•í•˜ì„¸ìš”! AI ìœ¤ë¦¬ì— ëŒ€í•´ ì´ì•¼ê¸°í•˜ê³  ì‹¶ìœ¼ì‹œêµ°ìš”. 
  â”‚    ì£¼ì œëŠ” AI ìœ¤ë¦¬ì…ë‹ˆë‹¤. ì´ëŠ”..."
  â”‚
  â–¼
[3] LangChain íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
  â”‚
  â”œâ”€â†’ ChatPromptTemplate
  â”‚   â””â”€â†’ "ë‹¤ìŒ ì‘ë‹µì„ JSON í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”..."
  â”‚
  â”œâ”€â†’ ChatOpenAI (gpt-4o-mini)
  â”‚   â””â”€â†’ JSON í˜•ì‹ìœ¼ë¡œ ë³€í™˜ëœ ì‘ë‹µ ìƒì„±
  â”‚
  â””â”€â†’ PydanticOutputParser
      â””â”€â†’ Pydantic ëª¨ë¸ë¡œ íŒŒì‹± ë° ê²€ì¦
  â”‚
  â–¼
[4] êµ¬ì¡°í™”ëœ ë³€ìˆ˜ ì¶”ì¶œ
  â”‚
  â”œâ”€â†’ parsed_variables = {
  â”‚     "topic": "AI ìœ¤ë¦¬"
  â”‚   }
  â”‚
  â””â”€â†’ response_text = "ì•ˆë…•í•˜ì„¸ìš”! AI ìœ¤ë¦¬ì— ëŒ€í•´ ì´ì•¼ê¸°í•˜ê³  ì‹¶ìœ¼ì‹œêµ°ìš”..."
  â”‚
  â–¼
[5] ì»¨í…ìŠ¤íŠ¸ì— ë³€ìˆ˜ ì €ì¥
  â”‚
  â”œâ”€â†’ context["opening_topic"] = "AI ìœ¤ë¦¬"
  â”‚
  â””â”€â†’ ë‹¤ìŒ ë‹¨ê³„(dilemma)ì—ì„œ ì‚¬ìš©
  â”‚
  â–¼
[6] API ì‘ë‹µ ë°˜í™˜
  â”‚
  â””â”€â†’ {
       "response_text": "...",
       "parsed_variables": {"topic": "AI ìœ¤ë¦¬"},
       "current_step": "opening",
       "next_step": "dilemma"
     }
```

### ì‹¤ì œ ì˜ˆì‹œ

**ì…ë ¥ (opening ë‹¨ê³„)**:
```json
{
  "session_id": "session-123",
  "user_input": "AI ìœ¤ë¦¬ì— ëŒ€í•´ ì´ì•¼ê¸°í•˜ê³  ì‹¶ì–´ìš”",
  "step": "opening"
}
```

**1ë‹¨ê³„: OpenAI Playground API ì‘ë‹µ**:
```
"ì•ˆë…•í•˜ì„¸ìš”! AI ìœ¤ë¦¬ì— ëŒ€í•´ ì´ì•¼ê¸°í•˜ê³  ì‹¶ìœ¼ì‹œêµ°ìš”. 
ì£¼ì œëŠ” AI ìœ¤ë¦¬ì…ë‹ˆë‹¤. ì´ëŠ” í˜„ëŒ€ ì‚¬íšŒì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ 
ìœ¤ë¦¬ì  ê³ ë¯¼ ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤..."
```

**2ë‹¨ê³„: LangChain íŒŒì‹± ê²°ê³¼**:
```json
{
  "response_text": "ì•ˆë…•í•˜ì„¸ìš”! AI ìœ¤ë¦¬ì— ëŒ€í•´ ì´ì•¼ê¸°í•˜ê³  ì‹¶ìœ¼ì‹œêµ°ìš”...",
  "topic": "AI ìœ¤ë¦¬"
}
```

**ìµœì¢… API ì‘ë‹µ**:
```json
{
  "session_id": "session-123",
  "current_step": "opening",
  "response_text": "ì•ˆë…•í•˜ì„¸ìš”! AI ìœ¤ë¦¬ì— ëŒ€í•´ ì´ì•¼ê¸°í•˜ê³  ì‹¶ìœ¼ì‹œêµ°ìš”...",
  "parsed_variables": {
    "topic": "AI ìœ¤ë¦¬"
  },
  "context": {
    "opening_topic": "AI ìœ¤ë¦¬"
  },
  "next_step": "dilemma",
  "is_complete": false
}
```

**ë‹¤ìŒ ë‹¨ê³„ (dilemma)ì—ì„œ topic ì‚¬ìš©**:
- `context`ì— `opening_topic`ì´ ì €ì¥ë˜ì–´ ìˆìœ¼ë¯€ë¡œ dilemma í”„ë¡¬í”„íŠ¸ì—ì„œ `{{topic}}` ë³€ìˆ˜ë¡œ ì‚¬ìš© ê°€ëŠ¥

---

## ì¥ë‹¨ì  ë¶„ì„

### ì¥ì  âœ…

1. **ë†’ì€ íŒŒì‹± ì„±ê³µë¥ **
   - LLMì´ LLM ì¶œë ¥ì„ íŒŒì‹±í•˜ë¯€ë¡œ ë‹¤ì–‘í•œ í˜•ì‹ì— ëŒ€ì‘ ê°€ëŠ¥
   - ì •ê·œí‘œí˜„ì‹ë³´ë‹¤ í›¨ì”¬ ìœ ì—°í•¨

2. **íƒ€ì… ì•ˆì „ì„±**
   - Pydantic ëª¨ë¸ë¡œ ìŠ¤í‚¤ë§ˆ ê°•ì œ ë° ìë™ ê²€ì¦
   - ëŸ°íƒ€ì„ íƒ€ì… ì²´í¬

3. **ìœ ì§€ë³´ìˆ˜ì„± í–¥ìƒ**
   - í”„ë¡¬í”„íŠ¸ ë³€ê²½ ì‹œ íŒŒì‹± ë¡œì§ ìˆ˜ì • ë¶ˆí•„ìš”
   - Pydantic ëª¨ë¸ë§Œ ìˆ˜ì •í•˜ë©´ ìë™ ë°˜ì˜

4. **Graceful Fallback**
   - íŒŒì‹± ì‹¤íŒ¨ ì‹œì—ë„ ì›ë³¸ í…ìŠ¤íŠ¸ ë°˜í™˜
   - ì„œë¹„ìŠ¤ ì¤‘ë‹¨ ì—†ì´ ì•ˆì •ì  ìš´ì˜

5. **ëª…í™•í•œ ìŠ¤í‚¤ë§ˆ ì •ì˜**
   - ê° ë‹¨ê³„ë³„ í•„ìš”í•œ ë³€ìˆ˜ê°€ ì½”ë“œì— ëª…ì‹œì ìœ¼ë¡œ ì •ì˜ë¨
   - ë¬¸ì„œí™” íš¨ê³¼

### ë‹¨ì  âŒ

1. **ì¶”ê°€ API í˜¸ì¶œ ë¹„ìš©**
   - OpenAI Playground API í˜¸ì¶œ + LangChain LLM í˜¸ì¶œ
   - ë¹„ìš©ì´ 2ë°°ë¡œ ì¦ê°€ (í•˜ì§€ë§Œ gpt-4o-mini ì‚¬ìš©ìœ¼ë¡œ ì ˆê°)

2. **ì‘ë‹µ ì‹œê°„ ì¦ê°€**
   - 2ë‹¨ê³„ ì²˜ë¦¬ë¡œ ì¸í•œ ì§€ì—° ì‹œê°„
   - ì•½ 1-2ì´ˆ ì¶”ê°€ ì†Œìš”

3. **ì˜ì¡´ì„± ì¦ê°€**
   - LangChain ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€
   - ì„¤ì¹˜ ì‹œê°„ ì¦ê°€ (ì˜ì¡´ì„±ì´ ë§ìŒ)

4. **ë³µì¡ë„ ì¦ê°€**
   - ì½”ë“œ ë³µì¡ë„ê°€ ë‹¤ì†Œ ì¦ê°€
   - ë””ë²„ê¹… ë‚œì´ë„ ìƒìŠ¹

### ë¹„ìš© ìµœì í™”

- **gpt-4o-mini ì‚¬ìš©**: íŒŒì‹±ìš©ìœ¼ë¡œëŠ” ì €ë ´í•œ ëª¨ë¸ ì‚¬ìš©
- **ìºì‹± ê³ ë ¤**: ë™ì¼í•œ ì…ë ¥ì— ëŒ€í•´ íŒŒì‹± ê²°ê³¼ ìºì‹± ê°€ëŠ¥
- **ì„ íƒì  íŒŒì‹±**: ì¤‘ìš”í•œ ë‹¨ê³„ì—ì„œë§Œ íŒŒì‹± ìˆ˜í–‰

---

## ì—ëŸ¬ ì²˜ë¦¬ ë° ì•ˆì •ì„±

### íŒŒì‹± ì‹¤íŒ¨ ì‹œë‚˜ë¦¬ì˜¤

```python
try:
    parsed_result = await chain.ainvoke({...})
except Exception as parse_error:
    # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì›ë³¸ í…ìŠ¤íŠ¸ ì‚¬ìš©
    parsed_variables = {}
    # ë¡œê¹… (ì„ íƒì )
    logger.warning(f"LangChain parsing failed: {parse_error}")
```

### ì•ˆì •ì„± ë³´ì¥

1. **Try-Except ë¸”ë¡**: íŒŒì‹± ì‹¤íŒ¨í•´ë„ ì„œë¹„ìŠ¤ ì¤‘ë‹¨ ì—†ìŒ
2. **Optional íƒ€ì…**: Pydantic í•„ë“œê°€ Optionalì´ë¯€ë¡œ None í—ˆìš©
3. **Fallback ë©”ì»¤ë‹ˆì¦˜**: íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì›ë³¸ í…ìŠ¤íŠ¸ ë°˜í™˜

---

## ì‹¤ì œ ì‚¬ìš© ì‚¬ë¡€

### ì¼€ì´ìŠ¤ 1: ë‹¤ë‹¨ê³„ ì±—ë´‡

```python
# opening ë‹¨ê³„ì—ì„œ topic ì¶”ì¶œ
response = await chat_service.process_multi_step_chat(
    db, 
    MultiStepChatRequest(
        session_id="session-123",
        user_input="AI ìœ¤ë¦¬ì— ëŒ€í•´ ì´ì•¼ê¸°í•˜ê³  ì‹¶ì–´ìš”",
        step="opening"
    )
)

# parsed_variablesì—ì„œ topic ì¶”ì¶œ
topic = response.parsed_variables.get("topic")  # "AI ìœ¤ë¦¬"

# ë‹¤ìŒ ë‹¨ê³„(dilemma)ì—ì„œ topic ì‚¬ìš©
# contextì— opening_topicì´ ìë™ìœ¼ë¡œ ì €ì¥ë˜ì–´ dilemma í”„ë¡¬í”„íŠ¸ì—ì„œ ì‚¬ìš© ê°€ëŠ¥
next_response = await chat_service.process_multi_step_chat(
    db,
    MultiStepChatRequest(
        session_id="session-123",
        user_input="...",
        step="dilemma"
    )
)
# dilemma ë‹¨ê³„ì—ì„œëŠ” question, choice1, choice2ë¥¼ ì¶”ì¶œí•˜ì—¬ flipì— ì „ë‹¬
```

### ì¼€ì´ìŠ¤ 2: ì´ë¯¸ì§€ ìƒì„±

```python
# ì‚¬ìš©ì ì…ë ¥ì„ êµ¬ì¡°í™”ëœ ì´ë¯¸ì§€ ì„¤ëª…ìœ¼ë¡œ ë³€í™˜
response = await generate_image(ImageRequest(
    input="AI ë¡œë´‡ê³¼ ì‚¬ëŒì´ ëŒ€í™”í•˜ëŠ” ì¥ë©´",
    context={"topic": "AI ìœ¤ë¦¬"}
))

# parsed_resultì—ì„œ ìƒì„¸ ì •ë³´ ì¶”ì¶œ
description = response.parsed_result["description"]
style = response.parsed_result["style"]
reasoning = response.parsed_result["reasoning"]
```

## ì°¸ê³  ìë£Œ

- [LangChain ê³µì‹ ë¬¸ì„œ](https://python.langchain.com/)
- [Pydantic ê³µì‹ ë¬¸ì„œ](https://docs.pydantic.dev/)
- [OpenAI Playground API](https://platform.openai.com/docs/guides/prompt-engineering)


